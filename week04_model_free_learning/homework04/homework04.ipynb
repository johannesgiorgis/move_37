{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment Week 4 - Q-Learning <a class=\"tocSkip\">\n",
    "\n",
    "This weeks homework assignment is to implement Q learning from scratch for the gridworld environment. Use this [repository](https://github.com/rlcode/reinforcement-learning/tree/master/1-grid-world) as a guide, but try not to peak at the Q learning code, recreate it, then check your code with it. Good luck!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-1\">Exercise</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.12</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.12, Latest is 1.1.13</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pixiedust\n",
    "import numpy as np\n",
    "import pprint\n",
    "from grid_world import standard_grid\n",
    "from utils import print_values, print_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "GAMMA = 0.95 # Discount factor from Bellman Equation\n",
    "# Track positions of interest in the grid\n",
    "POSITIONS = {\n",
    "    'START': (2, 0),\n",
    "    'WIN': (0, 3),\n",
    "    'LOSE': (1, 3)\n",
    "}\n",
    "\n",
    "\n",
    "# Helper Functions   \n",
    "def display_q(Q):\n",
    "    print('\\nQ Table:')\n",
    "    pprint.pprint(Q)\n",
    "\n",
    "    \n",
    "def report_q(Q):\n",
    "    for k in sorted(Q.keys()):\n",
    "        print(f\"{str(k):>6}\", end='->  ')\n",
    "        for j in sorted(Q[k].keys()):\n",
    "            print(f\"{j}: {Q[k][j]:>8.3}\", end=', ')\n",
    "        print(\"\")\n",
    "\n",
    "        \n",
    "def initialize_q(grid):\n",
    "    '''initialize Q(s,a) and returns'''\n",
    "    Q = {}\n",
    "    states = grid.non_terminal_states()\n",
    "    for s in states:\n",
    "        Q[s] = {}\n",
    "        for a in ALL_POSSIBLE_ACTIONS:\n",
    "            Q[s][a] = 0.0\n",
    "    return Q\n",
    "\n",
    "\n",
    "def epsilon_action(Q, state, epsilon=0.1):\n",
    "    '''epsilon greedy action selection'''\n",
    "    status = f'State: {state}'\n",
    "    #print(f'\\nState: {state}')\n",
    "    if np.random.random() < (1 - epsilon):\n",
    "        status += \". Following policy...\"\n",
    "        #print(Q[state])\n",
    "        #action = np.argmax(Q[state])\n",
    "        action = max(Q[state], key=Q[state].get)\n",
    "    else:\n",
    "        status += \". Following random policy...\"\n",
    "        action = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "    status += f\" Taking action '{action}'...\"\n",
    "    #print(f\"\\nStatus: '{status}'\")\n",
    "    return action\n",
    "\n",
    "\n",
    "def update_q(Q, prev_state, action, reward, curr_state):\n",
    "    #report_q(Q)\n",
    "    alpha = 0.1 # Learning Rate\n",
    "    #Q[prev_state][action] += alpha * (reward + GAMMA * max(Q[curr_state]) - Q[prev_state][action])\n",
    "    Q[prev_state][action] += alpha * (reward + GAMMA * Q[curr_state][max(Q[curr_state])] - Q[prev_state][action])\n",
    "    \n",
    "\n",
    "# Main Program\n",
    "def main(num_episodes=1000, epsilon=0.2, episode_window=1000):\n",
    "    \n",
    "    def print_episode_status():        \n",
    "        if curr_state in Q:\n",
    "            max_q = max(Q[curr_state])\n",
    "        else:\n",
    "            max_q = \"Terminal State\"\n",
    "        \n",
    "        print(f\"Turn: {turn:>5}| \"\n",
    "            f\"Previous State: {str(prev_state):>5}| \"\n",
    "            f\"Action: {action}| \"\n",
    "            f\"Actual Action: {actual_action}| \"\n",
    "            f\"\\nReward: {reward:>5.3f}| \"\n",
    "            f\"Curr State: {str(curr_state):>5}| \"\n",
    "            f\"Max Q: {max_q:>15}\")\n",
    "        \n",
    "        \n",
    "    # this grid gives you a reward of -0.1 for every non-terminal state\n",
    "    # we want to see if this will encourage finding a shorter path to the goal\n",
    "    grid = standard_grid(obey_prob=0.5, step_cost=-.5)\n",
    "\n",
    "    # print rewards\n",
    "    print(\"rewards:\")\n",
    "    print_values(grid.rewards, grid)\n",
    "    \n",
    "    Q = initialize_q(grid)\n",
    "    #print('Initial Q:')\n",
    "    #report_q(Q)\n",
    "    \n",
    "    total_reward = 0\n",
    "    \n",
    "    for episode in range(num_episodes + 1):\n",
    "        \n",
    "        if episode % episode_window == 0 and episode != 0:\n",
    "            avg_reward = total_reward/episode_window\n",
    "            print(f\"\\nEpisode = {episode}| Avg Reward = {avg_reward}\")\n",
    "            #report_q(Q)\n",
    "            total_reward = 0\n",
    "        \n",
    "        #if episode % 10000 == 0:\n",
    "        \n",
    "        # reset our position to starting position for new episode\n",
    "        if episode != 0:\n",
    "            grid.set_state(POSITIONS['START'])\n",
    "        \n",
    "        turn = 0\n",
    "        curr_state = grid.current_state()\n",
    "        #print(f\"\\n\\nStarting episode {episode} with current state at {curr_state}\")\n",
    "        \n",
    "        while not grid.game_over():\n",
    "            prev_state = curr_state\n",
    "            action = epsilon_action(Q, curr_state, epsilon=epsilon)\n",
    "            actual_action, reward = grid.move(action)\n",
    "            total_reward += reward\n",
    "            curr_state = grid.current_state()\n",
    "\n",
    "            #print_episode_status()\n",
    "            \n",
    "            # check if we reached end points\n",
    "            if grid.is_terminal(curr_state):\n",
    "                if curr_state == POSITIONS['WIN']:\n",
    "                    win_or_lose = 'WON'\n",
    "                else:\n",
    "                    win_or_lose = 'LOST'\n",
    "                #print(f\"\\nYOU {win_or_lose} episode {episode} with {turn + 1} turns!\")\n",
    "                break\n",
    "\n",
    "            update_q(Q, prev_state, action, reward, curr_state)\n",
    "            turn += 1\n",
    "\n",
    "        #print('Game over!')\n",
    "    #display_values(Q, returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.50|-0.50|-0.50| 1.00|\n",
      "---------------------------\n",
      "-0.50| 0.00|-0.50|-1.00|\n",
      "---------------------------\n",
      "-0.50|-0.50|-0.50|-0.50|\n",
      "\n",
      "Episode = 500| Avg Reward = -7.568\n",
      "\n",
      "Episode = 1000| Avg Reward = -6.923\n",
      "\n",
      "Episode = 1500| Avg Reward = -7.633\n",
      "\n",
      "Episode = 2000| Avg Reward = -7.415\n",
      "\n",
      "Episode = 2500| Avg Reward = -7.418\n",
      "\n",
      "Episode = 3000| Avg Reward = -7.181\n",
      "\n",
      "Episode = 3500| Avg Reward = -7.121\n",
      "\n",
      "Episode = 4000| Avg Reward = -7.472\n",
      "\n",
      "Episode = 4500| Avg Reward = -7.497\n",
      "\n",
      "Episode = 5000| Avg Reward = -7.994\n",
      "\n",
      "Episode = 5500| Avg Reward = -7.051\n",
      "\n",
      "Episode = 6000| Avg Reward = -7.566\n",
      "\n",
      "Episode = 6500| Avg Reward = -7.304\n",
      "\n",
      "Episode = 7000| Avg Reward = -7.481\n",
      "\n",
      "Episode = 7500| Avg Reward = -7.454\n",
      "\n",
      "Episode = 8000| Avg Reward = -7.156\n",
      "\n",
      "Episode = 8500| Avg Reward = -7.612\n",
      "\n",
      "Episode = 9000| Avg Reward = -7.383\n",
      "\n",
      "Episode = 9500| Avg Reward = -7.189\n",
      "\n",
      "Episode = 10000| Avg Reward = -7.435\n",
      "\n",
      "Episode = 10500| Avg Reward = -7.055\n",
      "\n",
      "Episode = 11000| Avg Reward = -7.507\n",
      "\n",
      "Episode = 11500| Avg Reward = -7.731\n",
      "\n",
      "Episode = 12000| Avg Reward = -7.504\n",
      "\n",
      "Episode = 12500| Avg Reward = -7.598\n",
      "\n",
      "Episode = 13000| Avg Reward = -7.661\n",
      "\n",
      "Episode = 13500| Avg Reward = -7.054\n",
      "\n",
      "Episode = 14000| Avg Reward = -7.739\n",
      "\n",
      "Episode = 14500| Avg Reward = -7.694\n",
      "\n",
      "Episode = 15000| Avg Reward = -7.036\n",
      "\n",
      "Episode = 15500| Avg Reward = -7.088\n",
      "\n",
      "Episode = 16000| Avg Reward = -7.79\n",
      "\n",
      "Episode = 16500| Avg Reward = -7.125\n",
      "\n",
      "Episode = 17000| Avg Reward = -7.627\n",
      "\n",
      "Episode = 17500| Avg Reward = -7.956\n",
      "\n",
      "Episode = 18000| Avg Reward = -7.203\n",
      "\n",
      "Episode = 18500| Avg Reward = -7.478\n",
      "\n",
      "Episode = 19000| Avg Reward = -7.664\n",
      "\n",
      "Episode = 19500| Avg Reward = -7.607\n",
      "\n",
      "Episode = 20000| Avg Reward = -7.421\n",
      "\n",
      "Episode = 20500| Avg Reward = -7.533\n",
      "\n",
      "Episode = 21000| Avg Reward = -7.546\n",
      "\n",
      "Episode = 21500| Avg Reward = -7.641\n",
      "\n",
      "Episode = 22000| Avg Reward = -7.802\n",
      "\n",
      "Episode = 22500| Avg Reward = -7.518\n",
      "\n",
      "Episode = 23000| Avg Reward = -12.168\n",
      "\n",
      "Episode = 23500| Avg Reward = -12.354\n",
      "\n",
      "Episode = 24000| Avg Reward = -11.781\n",
      "\n",
      "Episode = 24500| Avg Reward = -11.696\n",
      "\n",
      "Episode = 25000| Avg Reward = -12.349\n",
      "\n",
      "Episode = 25500| Avg Reward = -11.925\n",
      "\n",
      "Episode = 26000| Avg Reward = -12.372\n",
      "\n",
      "Episode = 26500| Avg Reward = -12.351\n",
      "\n",
      "Episode = 27000| Avg Reward = -11.986\n",
      "\n",
      "Episode = 27500| Avg Reward = -12.085\n",
      "\n",
      "Episode = 28000| Avg Reward = -11.701\n",
      "\n",
      "Episode = 28500| Avg Reward = -11.533\n",
      "\n",
      "Episode = 29000| Avg Reward = -12.564\n",
      "\n",
      "Episode = 29500| Avg Reward = -12.016\n",
      "\n",
      "Episode = 30000| Avg Reward = -12.095\n",
      "\n",
      "Episode = 30500| Avg Reward = -11.676\n",
      "\n",
      "Episode = 31000| Avg Reward = -11.089\n",
      "\n",
      "Episode = 31500| Avg Reward = -11.822\n",
      "\n",
      "Episode = 32000| Avg Reward = -12.379\n",
      "\n",
      "Episode = 32500| Avg Reward = -11.69\n",
      "\n",
      "Episode = 33000| Avg Reward = -11.894\n",
      "\n",
      "Episode = 33500| Avg Reward = -12.511\n",
      "\n",
      "Episode = 34000| Avg Reward = -12.816\n",
      "\n",
      "Episode = 34500| Avg Reward = -12.185\n",
      "\n",
      "Episode = 35000| Avg Reward = -11.732\n",
      "\n",
      "Episode = 35500| Avg Reward = -12.033\n",
      "\n",
      "Episode = 36000| Avg Reward = -11.996\n",
      "\n",
      "Episode = 36500| Avg Reward = -12.053\n",
      "\n",
      "Episode = 37000| Avg Reward = -11.769\n",
      "\n",
      "Episode = 37500| Avg Reward = -11.426\n",
      "\n",
      "Episode = 38000| Avg Reward = -12.828\n",
      "\n",
      "Episode = 38500| Avg Reward = -12.311\n",
      "\n",
      "Episode = 39000| Avg Reward = -11.924\n",
      "\n",
      "Episode = 39500| Avg Reward = -12.461\n",
      "\n",
      "Episode = 40000| Avg Reward = -12.015\n",
      "\n",
      "Episode = 40500| Avg Reward = -12.332\n",
      "\n",
      "Episode = 41000| Avg Reward = -12.733\n",
      "\n",
      "Episode = 41500| Avg Reward = -11.682\n",
      "\n",
      "Episode = 42000| Avg Reward = -11.706\n",
      "\n",
      "Episode = 42500| Avg Reward = -11.642\n",
      "\n",
      "Episode = 43000| Avg Reward = -11.991\n",
      "\n",
      "Episode = 43500| Avg Reward = -12.488\n",
      "\n",
      "Episode = 44000| Avg Reward = -12.396\n",
      "\n",
      "Episode = 44500| Avg Reward = -12.211\n",
      "\n",
      "Episode = 45000| Avg Reward = -11.933\n",
      "\n",
      "Episode = 45500| Avg Reward = -11.639\n",
      "\n",
      "Episode = 46000| Avg Reward = -12.129\n",
      "\n",
      "Episode = 46500| Avg Reward = -11.679\n",
      "\n",
      "Episode = 47000| Avg Reward = -11.392\n",
      "\n",
      "Episode = 47500| Avg Reward = -12.043\n",
      "\n",
      "Episode = 48000| Avg Reward = -11.812\n",
      "\n",
      "Episode = 48500| Avg Reward = -11.994\n",
      "\n",
      "Episode = 49000| Avg Reward = -11.877\n",
      "\n",
      "Episode = 49500| Avg Reward = -11.942\n",
      "\n",
      "Episode = 50000| Avg Reward = -12.853\n",
      "\n",
      "Episode = 50500| Avg Reward = -11.795\n",
      "\n",
      "Episode = 51000| Avg Reward = -12.713\n",
      "\n",
      "Episode = 51500| Avg Reward = -11.232\n",
      "\n",
      "Episode = 52000| Avg Reward = -12.017\n",
      "\n",
      "Episode = 52500| Avg Reward = -12.533\n",
      "\n",
      "Episode = 53000| Avg Reward = -10.781\n",
      "\n",
      "Episode = 53500| Avg Reward = -11.733\n",
      "\n",
      "Episode = 54000| Avg Reward = -12.29\n",
      "\n",
      "Episode = 54500| Avg Reward = -12.157\n",
      "\n",
      "Episode = 55000| Avg Reward = -12.191\n",
      "\n",
      "Episode = 55500| Avg Reward = -11.699\n",
      "\n",
      "Episode = 56000| Avg Reward = -12.267\n",
      "\n",
      "Episode = 56500| Avg Reward = -11.629\n",
      "\n",
      "Episode = 57000| Avg Reward = -10.73\n",
      "\n",
      "Episode = 57500| Avg Reward = -10.364\n",
      "\n",
      "Episode = 58000| Avg Reward = -12.396\n",
      "\n",
      "Episode = 58500| Avg Reward = -11.572\n",
      "\n",
      "Episode = 59000| Avg Reward = -12.138\n",
      "\n",
      "Episode = 59500| Avg Reward = -13.385\n",
      "\n",
      "Episode = 60000| Avg Reward = -11.771\n",
      "\n",
      "Episode = 60500| Avg Reward = -12.166\n",
      "\n",
      "Episode = 61000| Avg Reward = -12.334\n",
      "\n",
      "Episode = 61500| Avg Reward = -11.975\n",
      "\n",
      "Episode = 62000| Avg Reward = -12.214\n",
      "\n",
      "Episode = 62500| Avg Reward = -11.071\n",
      "\n",
      "Episode = 63000| Avg Reward = -11.619\n",
      "\n",
      "Episode = 63500| Avg Reward = -10.995\n",
      "\n",
      "Episode = 64000| Avg Reward = -12.474\n",
      "\n",
      "Episode = 64500| Avg Reward = -11.726\n",
      "\n",
      "Episode = 65000| Avg Reward = -12.122\n",
      "\n",
      "Episode = 65500| Avg Reward = -11.672\n",
      "\n",
      "Episode = 66000| Avg Reward = -11.271\n",
      "\n",
      "Episode = 66500| Avg Reward = -12.637\n",
      "\n",
      "Episode = 67000| Avg Reward = -12.289\n",
      "\n",
      "Episode = 67500| Avg Reward = -11.903\n",
      "\n",
      "Episode = 68000| Avg Reward = -11.702\n",
      "\n",
      "Episode = 68500| Avg Reward = -12.112\n",
      "\n",
      "Episode = 69000| Avg Reward = -11.942\n",
      "\n",
      "Episode = 69500| Avg Reward = -12.077\n",
      "\n",
      "Episode = 70000| Avg Reward = -11.8\n",
      "\n",
      "Episode = 70500| Avg Reward = -11.91\n",
      "\n",
      "Episode = 71000| Avg Reward = -12.113\n",
      "\n",
      "Episode = 71500| Avg Reward = -12.053\n",
      "\n",
      "Episode = 72000| Avg Reward = -11.193\n",
      "\n",
      "Episode = 72500| Avg Reward = -11.961\n",
      "\n",
      "Episode = 73000| Avg Reward = -11.506\n",
      "\n",
      "Episode = 73500| Avg Reward = -12.456\n",
      "\n",
      "Episode = 74000| Avg Reward = -12.008\n",
      "\n",
      "Episode = 74500| Avg Reward = -11.532\n",
      "\n",
      "Episode = 75000| Avg Reward = -12.183\n",
      "\n",
      "Episode = 75500| Avg Reward = -11.612\n",
      "\n",
      "Episode = 76000| Avg Reward = -12.063\n",
      "\n",
      "Episode = 76500| Avg Reward = -12.002\n",
      "\n",
      "Episode = 77000| Avg Reward = -12.044\n",
      "\n",
      "Episode = 77500| Avg Reward = -13.083\n",
      "\n",
      "Episode = 78000| Avg Reward = -11.988\n",
      "\n",
      "Episode = 78500| Avg Reward = -12.299\n",
      "\n",
      "Episode = 79000| Avg Reward = -12.631\n",
      "\n",
      "Episode = 79500| Avg Reward = -12.751\n",
      "\n",
      "Episode = 80000| Avg Reward = -12.404\n",
      "\n",
      "Episode = 80500| Avg Reward = -12.21\n",
      "\n",
      "Episode = 81000| Avg Reward = -11.511\n",
      "\n",
      "Episode = 81500| Avg Reward = -11.604\n",
      "\n",
      "Episode = 82000| Avg Reward = -11.961\n",
      "\n",
      "Episode = 82500| Avg Reward = -11.832\n",
      "\n",
      "Episode = 83000| Avg Reward = -12.685\n",
      "\n",
      "Episode = 83500| Avg Reward = -12.005\n",
      "\n",
      "Episode = 84000| Avg Reward = -11.9\n",
      "\n",
      "Episode = 84500| Avg Reward = -12.468\n",
      "\n",
      "Episode = 85000| Avg Reward = -11.865\n",
      "\n",
      "Episode = 85500| Avg Reward = -12.07\n",
      "\n",
      "Episode = 86000| Avg Reward = -12.138\n",
      "\n",
      "Episode = 86500| Avg Reward = -12.927\n",
      "\n",
      "Episode = 87000| Avg Reward = -12.984\n",
      "\n",
      "Episode = 87500| Avg Reward = -12.138\n",
      "\n",
      "Episode = 88000| Avg Reward = -11.686\n",
      "\n",
      "Episode = 88500| Avg Reward = -12.325\n",
      "\n",
      "Episode = 89000| Avg Reward = -11.164\n",
      "\n",
      "Episode = 89500| Avg Reward = -12.137\n",
      "\n",
      "Episode = 90000| Avg Reward = -12.7\n",
      "\n",
      "Episode = 90500| Avg Reward = -12.021\n",
      "\n",
      "Episode = 91000| Avg Reward = -12.33\n",
      "\n",
      "Episode = 91500| Avg Reward = -11.962\n",
      "\n",
      "Episode = 92000| Avg Reward = -11.734\n",
      "\n",
      "Episode = 92500| Avg Reward = -13.111\n",
      "\n",
      "Episode = 93000| Avg Reward = -11.862\n",
      "\n",
      "Episode = 93500| Avg Reward = -11.855\n",
      "\n",
      "Episode = 94000| Avg Reward = -11.915\n",
      "\n",
      "Episode = 94500| Avg Reward = -12.23\n",
      "\n",
      "Episode = 95000| Avg Reward = -12.032\n",
      "\n",
      "Episode = 95500| Avg Reward = -11.798\n",
      "\n",
      "Episode = 96000| Avg Reward = -12.362\n",
      "\n",
      "Episode = 96500| Avg Reward = -11.19\n",
      "\n",
      "Episode = 97000| Avg Reward = -12.493\n",
      "\n",
      "Episode = 97500| Avg Reward = -12.565\n",
      "\n",
      "Episode = 98000| Avg Reward = -11.515\n",
      "\n",
      "Episode = 98500| Avg Reward = -13.028\n",
      "\n",
      "Episode = 99000| Avg Reward = -13.118\n",
      "\n",
      "Episode = 99500| Avg Reward = -12.399\n",
      "\n",
      "Episode = 100000| Avg Reward = -12.131\n"
     ]
    }
   ],
   "source": [
    "#%pixie_debugger\n",
    "main(num_episodes=100000, episode_window=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
